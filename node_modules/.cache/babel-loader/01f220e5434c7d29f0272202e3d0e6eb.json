{"ast":null,"code":"'use strict';\n\nObject.defineProperty(exports, '__esModule', {\n  value: true\n});\nexports.stripIgnoredCharacters = stripIgnoredCharacters;\n\nvar _blockString = require('../language/blockString.js');\n\nvar _lexer = require('../language/lexer.js');\n\nvar _source = require('../language/source.js');\n\nvar _tokenKind = require('../language/tokenKind.js');\n/**\n * Strips characters that are not significant to the validity or execution\n * of a GraphQL document:\n *   - UnicodeBOM\n *   - WhiteSpace\n *   - LineTerminator\n *   - Comment\n *   - Comma\n *   - BlockString indentation\n *\n * Note: It is required to have a delimiter character between neighboring\n * non-punctuator tokens and this function always uses single space as delimiter.\n *\n * It is guaranteed that both input and output documents if parsed would result\n * in the exact same AST except for nodes location.\n *\n * Warning: It is guaranteed that this function will always produce stable results.\n * However, it's not guaranteed that it will stay the same between different\n * releases due to bugfixes or changes in the GraphQL specification.\n *\n * Query example:\n *\n * ```graphql\n * query SomeQuery($foo: String!, $bar: String) {\n *   someField(foo: $foo, bar: $bar) {\n *     a\n *     b {\n *       c\n *       d\n *     }\n *   }\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * query SomeQuery($foo:String!$bar:String){someField(foo:$foo bar:$bar){a b{c d}}}\n * ```\n *\n * SDL example:\n *\n * ```graphql\n * \"\"\"\n * Type description\n * \"\"\"\n * type Foo {\n *   \"\"\"\n *   Field description\n *   \"\"\"\n *   bar: String\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * \"\"\"Type description\"\"\" type Foo{\"\"\"Field description\"\"\" bar:String}\n * ```\n */\n\n\nfunction stripIgnoredCharacters(source) {\n  const sourceObj = (0, _source.isSource)(source) ? source : new _source.Source(source);\n  const body = sourceObj.body;\n  const lexer = new _lexer.Lexer(sourceObj);\n  let strippedBody = '';\n  let wasLastAddedTokenNonPunctuator = false;\n\n  while (lexer.advance().kind !== _tokenKind.TokenKind.EOF) {\n    const currentToken = lexer.token;\n    const tokenKind = currentToken.kind;\n    /**\n     * Every two non-punctuator tokens should have space between them.\n     * Also prevent case of non-punctuator token following by spread resulting\n     * in invalid token (e.g. `1...` is invalid Float token).\n     */\n\n    const isNonPunctuator = !(0, _lexer.isPunctuatorTokenKind)(currentToken.kind);\n\n    if (wasLastAddedTokenNonPunctuator) {\n      if (isNonPunctuator || currentToken.kind === _tokenKind.TokenKind.SPREAD) {\n        strippedBody += ' ';\n      }\n    }\n\n    const tokenBody = body.slice(currentToken.start, currentToken.end);\n\n    if (tokenKind === _tokenKind.TokenKind.BLOCK_STRING) {\n      strippedBody += (0, _blockString.printBlockString)(currentToken.value, {\n        minimize: true\n      });\n    } else {\n      strippedBody += tokenBody;\n    }\n\n    wasLastAddedTokenNonPunctuator = isNonPunctuator;\n  }\n\n  return strippedBody;\n}","map":{"version":3,"sources":["/home/atefeh/Documents/my-project/netflix/node_modules/graphql/utilities/stripIgnoredCharacters.js"],"names":["Object","defineProperty","exports","value","stripIgnoredCharacters","_blockString","require","_lexer","_source","_tokenKind","source","sourceObj","isSource","Source","body","lexer","Lexer","strippedBody","wasLastAddedTokenNonPunctuator","advance","kind","TokenKind","EOF","currentToken","token","tokenKind","isNonPunctuator","isPunctuatorTokenKind","SPREAD","tokenBody","slice","start","end","BLOCK_STRING","printBlockString","minimize"],"mappings":"AAAA;;AAEAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAC3CC,EAAAA,KAAK,EAAE;AADoC,CAA7C;AAGAD,OAAO,CAACE,sBAAR,GAAiCA,sBAAjC;;AAEA,IAAIC,YAAY,GAAGC,OAAO,CAAC,4BAAD,CAA1B;;AAEA,IAAIC,MAAM,GAAGD,OAAO,CAAC,sBAAD,CAApB;;AAEA,IAAIE,OAAO,GAAGF,OAAO,CAAC,uBAAD,CAArB;;AAEA,IAAIG,UAAU,GAAGH,OAAO,CAAC,0BAAD,CAAxB;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASF,sBAAT,CAAgCM,MAAhC,EAAwC;AACtC,QAAMC,SAAS,GAAG,CAAC,GAAGH,OAAO,CAACI,QAAZ,EAAsBF,MAAtB,IACdA,MADc,GAEd,IAAIF,OAAO,CAACK,MAAZ,CAAmBH,MAAnB,CAFJ;AAGA,QAAMI,IAAI,GAAGH,SAAS,CAACG,IAAvB;AACA,QAAMC,KAAK,GAAG,IAAIR,MAAM,CAACS,KAAX,CAAiBL,SAAjB,CAAd;AACA,MAAIM,YAAY,GAAG,EAAnB;AACA,MAAIC,8BAA8B,GAAG,KAArC;;AAEA,SAAOH,KAAK,CAACI,OAAN,GAAgBC,IAAhB,KAAyBX,UAAU,CAACY,SAAX,CAAqBC,GAArD,EAA0D;AACxD,UAAMC,YAAY,GAAGR,KAAK,CAACS,KAA3B;AACA,UAAMC,SAAS,GAAGF,YAAY,CAACH,IAA/B;AACA;AACJ;AACA;AACA;AACA;;AAEI,UAAMM,eAAe,GAAG,CAAC,CAAC,GAAGnB,MAAM,CAACoB,qBAAX,EACvBJ,YAAY,CAACH,IADU,CAAzB;;AAIA,QAAIF,8BAAJ,EAAoC;AAClC,UACEQ,eAAe,IACfH,YAAY,CAACH,IAAb,KAAsBX,UAAU,CAACY,SAAX,CAAqBO,MAF7C,EAGE;AACAX,QAAAA,YAAY,IAAI,GAAhB;AACD;AACF;;AAED,UAAMY,SAAS,GAAGf,IAAI,CAACgB,KAAL,CAAWP,YAAY,CAACQ,KAAxB,EAA+BR,YAAY,CAACS,GAA5C,CAAlB;;AAEA,QAAIP,SAAS,KAAKhB,UAAU,CAACY,SAAX,CAAqBY,YAAvC,EAAqD;AACnDhB,MAAAA,YAAY,IAAI,CAAC,GAAGZ,YAAY,CAAC6B,gBAAjB,EAAmCX,YAAY,CAACpB,KAAhD,EAAuD;AACrEgC,QAAAA,QAAQ,EAAE;AAD2D,OAAvD,CAAhB;AAGD,KAJD,MAIO;AACLlB,MAAAA,YAAY,IAAIY,SAAhB;AACD;;AAEDX,IAAAA,8BAA8B,GAAGQ,eAAjC;AACD;;AAED,SAAOT,YAAP;AACD","sourcesContent":["'use strict';\n\nObject.defineProperty(exports, '__esModule', {\n  value: true,\n});\nexports.stripIgnoredCharacters = stripIgnoredCharacters;\n\nvar _blockString = require('../language/blockString.js');\n\nvar _lexer = require('../language/lexer.js');\n\nvar _source = require('../language/source.js');\n\nvar _tokenKind = require('../language/tokenKind.js');\n\n/**\n * Strips characters that are not significant to the validity or execution\n * of a GraphQL document:\n *   - UnicodeBOM\n *   - WhiteSpace\n *   - LineTerminator\n *   - Comment\n *   - Comma\n *   - BlockString indentation\n *\n * Note: It is required to have a delimiter character between neighboring\n * non-punctuator tokens and this function always uses single space as delimiter.\n *\n * It is guaranteed that both input and output documents if parsed would result\n * in the exact same AST except for nodes location.\n *\n * Warning: It is guaranteed that this function will always produce stable results.\n * However, it's not guaranteed that it will stay the same between different\n * releases due to bugfixes or changes in the GraphQL specification.\n *\n * Query example:\n *\n * ```graphql\n * query SomeQuery($foo: String!, $bar: String) {\n *   someField(foo: $foo, bar: $bar) {\n *     a\n *     b {\n *       c\n *       d\n *     }\n *   }\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * query SomeQuery($foo:String!$bar:String){someField(foo:$foo bar:$bar){a b{c d}}}\n * ```\n *\n * SDL example:\n *\n * ```graphql\n * \"\"\"\n * Type description\n * \"\"\"\n * type Foo {\n *   \"\"\"\n *   Field description\n *   \"\"\"\n *   bar: String\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * \"\"\"Type description\"\"\" type Foo{\"\"\"Field description\"\"\" bar:String}\n * ```\n */\nfunction stripIgnoredCharacters(source) {\n  const sourceObj = (0, _source.isSource)(source)\n    ? source\n    : new _source.Source(source);\n  const body = sourceObj.body;\n  const lexer = new _lexer.Lexer(sourceObj);\n  let strippedBody = '';\n  let wasLastAddedTokenNonPunctuator = false;\n\n  while (lexer.advance().kind !== _tokenKind.TokenKind.EOF) {\n    const currentToken = lexer.token;\n    const tokenKind = currentToken.kind;\n    /**\n     * Every two non-punctuator tokens should have space between them.\n     * Also prevent case of non-punctuator token following by spread resulting\n     * in invalid token (e.g. `1...` is invalid Float token).\n     */\n\n    const isNonPunctuator = !(0, _lexer.isPunctuatorTokenKind)(\n      currentToken.kind,\n    );\n\n    if (wasLastAddedTokenNonPunctuator) {\n      if (\n        isNonPunctuator ||\n        currentToken.kind === _tokenKind.TokenKind.SPREAD\n      ) {\n        strippedBody += ' ';\n      }\n    }\n\n    const tokenBody = body.slice(currentToken.start, currentToken.end);\n\n    if (tokenKind === _tokenKind.TokenKind.BLOCK_STRING) {\n      strippedBody += (0, _blockString.printBlockString)(currentToken.value, {\n        minimize: true,\n      });\n    } else {\n      strippedBody += tokenBody;\n    }\n\n    wasLastAddedTokenNonPunctuator = isNonPunctuator;\n  }\n\n  return strippedBody;\n}\n"]},"metadata":{},"sourceType":"script"}